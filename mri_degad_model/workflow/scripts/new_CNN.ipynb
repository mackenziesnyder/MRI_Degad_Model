{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c244be88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m302.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting monai\n",
      "  Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nibabel\n",
      "  Downloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m279.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m238.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m269.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m208.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m220.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m238.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m166.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m164.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m235.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m220.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m253.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m243.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.2.0\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m215.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /home/UWO/msnyde26/.local/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m302.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 KB\u001b[0m \u001b[31m282.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m268.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m240.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m237.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m233.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m277.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m279.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m267.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m256.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m256.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m223.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.0,>=1.24\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m208.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20 in /usr/lib/python3/dist-packages (from nibabel) (21.3)\n",
      "Collecting importlib-resources>=5.12\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m277.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, threadpoolctl, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, joblib, importlib-resources, fsspec, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nibabel, nvidia-cusolver-cu12, torch, monai\n",
      "Successfully installed fsspec-2025.3.2 importlib-resources-6.5.2 joblib-1.4.2 monai-1.4.0 mpmath-1.3.0 networkx-3.4.2 nibabel-5.3.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 scikit-learn-1.6.1 sympy-1.13.1 threadpoolctl-3.6.0 torch-2.6.0 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch monai nibabel scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764c4bc",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cdc43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import glob \n",
    "import os\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Rand3DElasticd,\n",
    "    SpatialPadd,\n",
    "    RandFlipd,\n",
    "    RandSpatialCropd,\n",
    "    ToTensord\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "import time\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "from monai.utils import progress_bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.inferers import sliding_window_inference\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c502ba9",
   "metadata": {},
   "source": [
    "Model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5587dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test\n",
    "# patch_size = (16, 32)\n",
    "# batch_size = (32, 64, 128)\n",
    "# lr = (0.0001, 0.001, 0.01)\n",
    "# filter_num = (16, 32, 64)\n",
    "# depth = (3, 4)\n",
    "# num_conv = (2, 3)\n",
    "# loss_func = \"mae\"\n",
    "\n",
    "patch_size = 32\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "filter = 32\n",
    "depth = 3\n",
    "num_conv = 2\n",
    "loss_func = \"mae\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b50c4c",
   "metadata": {},
   "source": [
    "create output directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e079ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"output/patch-{patch_size}_batch-{batch_size}_LR-{lr}_filter-{filter}_depth-{depth}_convs-{num_conv}_loss-{loss_func}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f09751",
   "metadata": {},
   "source": [
    "Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46579389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available \n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32da08",
   "metadata": {},
   "source": [
    "Move preprocessed data to one input folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3634f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects:  ['/localscratch/output/work/sub-P005']\n",
      "sub:  /localscratch/output/work/sub-P005\n",
      "gad imag ['/localscratch/output/work/sub-P005/ses-pre/normalize/sub-P005_ses-pre_acq-nongad_run-01_desc-normalized_zscore_T1w.nii.gz']\n",
      "Loaded 1 paired samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# bids input folder to subject folders from preprocessing output \n",
    "bids_root = \"/localscratch/output/\"\n",
    "\n",
    "# subject folders \n",
    "subjects = sorted(glob.glob(os.path.join(bids_root, \"work\", \"sub-*\")))\n",
    "print(\"subjects: \", subjects)\n",
    "\n",
    "data_dicts = []\n",
    "\n",
    "# create a dictonary of matching gad and nogad files\n",
    "for sub in subjects:\n",
    "    print(\"sub: \", sub)\n",
    "    gad_images = glob.glob(os.path.join(sub, \"ses-pre\", \"normalize\", \"*acq-nongad*_T1w.nii.gz\"))\n",
    "    print(\"gad imag\", gad_images)\n",
    "    nogad_images = glob.glob(os.path.join(sub, \"ses-pre\", \"normalize\",\"*acq-nongad*_T1w.nii.gz\"))\n",
    "    if gad_images and nogad_images:\n",
    "        data_dicts.append({\"image\": gad_images[0], \"label\": nogad_images[0]})\n",
    "\n",
    "print(\"Loaded\", len(data_dicts), \"paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699898c6",
   "metadata": {},
   "source": [
    "Split into train, test, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da63673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train, 15% val, 15% test \n",
    "\n",
    "train_val, test = train_test_split(data_dicts, test_size=0.15, random_state=42)\n",
    "\n",
    "# 0.176 ≈ 15% of the full data\n",
    "train, val = train_test_split(train_val, test_size=0.176, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4da5e",
   "metadata": {},
   "source": [
    "Define transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using transformations from original code \n",
    "\n",
    "# set size of image to patch size (patch_size, patch_size, patch_size)\n",
    "dims_tuple = (patch_size,)*3\n",
    "\n",
    "# want to train with patches\n",
    "train_transforms = Compose([\n",
    "    SpatialPadd(keys = (\"image\",\"label\"), spatial_size = dims_tuple), #ensures all data is around the same size\n",
    "    Rand3DElasticd(keys = (\"image\",\"label\"), sigma_range = (0.5,1), magnitude_range = (0.1, 0.4), prob=0.4, shear_range=(0.1, -0.05, 0.0, 0.0, 0.0, 0.0), scale_range=0.5, padding_mode= \"zeros\"),\n",
    "    RandFlipd(keys = (\"image\",\"label\"), prob = 0.5, spatial_axis=1),\n",
    "    RandFlipd(keys = (\"image\",\"label\"), prob = 0.5, spatial_axis=0),\n",
    "    RandFlipd(keys = (\"image\",\"label\"), prob = 0.5, spatial_axis=2),\n",
    "    RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=patch_size, random_center=True, random_size=False),\n",
    "    ToTensord(keys=[\"image\", \"label\"])\n",
    "])\n",
    "\n",
    "# want to validate and test with whole images \n",
    "val_transforms = Compose([\n",
    "    SpatialPadd(keys = (\"image\",\"label\"),spatial_size = dims_tuple),\n",
    "    ToTensord(keys=[\"image\", \"label\"])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a34313",
   "metadata": {},
   "source": [
    "Set up datasets and data loader with monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef550ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = Dataset(data=train, transform=train_transforms)\n",
    "val_ds = Dataset(data=val, transform=val_transforms)\n",
    "test_ds = Dataset(data=test, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, num_workers=32, pin_memory=pin_memory)\n",
    "\n",
    "# val and test on whole brain data \n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=2, pin_memory=pin_memory)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=2, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e81649",
   "metadata": {},
   "source": [
    "Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate channels and strides based on given parameters\n",
    "\n",
    "# if depth is 3, and filter is 16, channels = 16, 32, 64\n",
    "channels = []\n",
    "for i in range(depth):\n",
    "    channels.append(filter)\n",
    "    filter *=2\n",
    "print(\"channels: \", channels)\n",
    "\n",
    "# if depth is 3, strides = 2, 2, 1 \n",
    "strides = []\n",
    "for i in range(depth - 1):\n",
    "    strides.append(2)\n",
    "strides.append(1)\n",
    "print(\"strides: \", strides)\n",
    "\n",
    "# define model \n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=channels,\n",
    "    strides=strides,\n",
    "    num_res_units=2,\n",
    "    dropout=0.2,\n",
    "    norm='BATCH'\n",
    ").apply(monai.networks.normal_init).to(device)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea381b",
   "metadata": {},
   "source": [
    "Define lr, optimization, epochs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = float(lr)\n",
    "\n",
    "# common defaults\n",
    "betas = (0.5, 0.999)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas=betas)\n",
    "\n",
    "patience = 22 # epochs it will take for training to terminate if no improvement\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, path = f'{output_dir}/checkpoint.pt')\n",
    "max_epochs = 800\n",
    "\n",
    "loss = torch.nn.L1Loss().to(device)\n",
    "\n",
    "train_losses = [float('inf')]\n",
    "val_losses = [float('inf')]\n",
    "test_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a74d64",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7898ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    progress_bar(\n",
    "        index=epoch+1, # displays what step we are of current epoch, our epoch number, training  loss\n",
    "        count = max_epochs, \n",
    "        desc= f\"epoch {epoch + 1}, training mae loss: {train_losses[-1]:.4f}, validation mae metric: {val_losses[-1]:.4f}\",\n",
    "        newline = True) # progress bar to display current stage in training\n",
    "    \n",
    "    # training\n",
    "    avg_train_loss = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # image is gad image, label is nogad image\n",
    "        gad_images, nogad_images = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        optimizer.zero_grad() #resets optimizer to 0\n",
    "        degad_images = model(gad_images)\n",
    "\n",
    "        train_loss = loss(degad_images, nogad_images)\n",
    "        train_loss.backward() # computes gradients for each parameter based on loss\n",
    "        optimizer.step() # updates the model weights using the gradient\n",
    "        avg_train_loss += train_loss.item() \n",
    "   \n",
    "    avg_train_loss /= len(train_loader) # average loss per current epoch \n",
    "    train_losses.append(avg_train_loss) # append total epoch loss divided by the number of training steps in epoch to loss list\n",
    "    model.eval()\n",
    "    \n",
    "    # validation \n",
    "    with torch.no_grad(): #we do not update weights/biases in validation training, only used to assess current state of model\n",
    "        avg_val_loss = 0 # will hold sum of all validation losses in epoch and then average\n",
    "        for i, batch in enumerate(val_loader): # iterating through dataloader\n",
    "            gad_images, nogad_images = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "            degad_images = model(gad_images)\n",
    "            \n",
    "            val_loss = loss(degad_images, nogad_images)\n",
    "            avg_val_loss += val_loss.item() \n",
    "        \n",
    "        avg_val_loss /= len(val_loader) #producing average val loss for this epoch\n",
    "        val_losses.append(avg_val_loss) \n",
    "        early_stopping(avg_val_loss, model) # early stopping keeps track of last best model\n",
    "\n",
    "    if early_stopping.early_stop: # stops early if validation loss has not improved for {patience} number of epochs\n",
    "        print(\"Early stopping, saving model\") \n",
    "        break\n",
    "\n",
    "end = time.time()\n",
    "time = end - start\n",
    "print(\"time for training and validation: \", time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e97b9b",
   "metadata": {},
   "source": [
    "Plot training metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from original code \n",
    "\n",
    "with open (f'{output_dir}/model_stats.txt', 'w') as file:  \n",
    "    file.write(f'Training time: {time}\\n') \n",
    "    file.write(f'Number of trainable parameters: {trainable_params}\\n')\n",
    "    file.write(f'Training loss: {train_losses[-patience]} \\nValidation loss: {early_stopping.val_loss_min}')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(list(range(len(train_losses))), train_losses, label=\"Training Loss\")\n",
    "plt.plot(list(range(len(val_losses))),val_losses , label=\"Validation Loss\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{output_dir}/lossfunction.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0c76a",
   "metadata": {},
   "source": [
    "Test model with sliding window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{output_dir}/checkpoint.pt'))\n",
    "model.eval()\n",
    "\n",
    "output_dir_test = Path(output_dir) / \"test\"\n",
    "output_dir_test.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        gad_images, nogad_images = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        degad_images = sliding_window_inference(gad_images, patch_size, 1, model)\n",
    "\n",
    "        loss_value = loss(degad_images, nogad_images)\n",
    "\n",
    "        test_loss += loss_value.item()\n",
    "\n",
    "        # to save the output files \n",
    "        # shape[0] gives number of images \n",
    "        for i in range(degad_images.shape[0]):\n",
    "            gad_path = batch[\"image_meta_dict\"][\"filename_or_obj\"][i]\n",
    "            gad_nib = nib.load(gad_path)\n",
    "            sub = Path(gad_path).name.split(\"_\")[0] \n",
    "            degad_name = f\"{sub}_acq-degad_T1w.nii.gz\"\n",
    "            \n",
    "            degad_nib = nib.Nifti1Image(\n",
    "                degad_images[i, 0].detach().numpy()*100, \n",
    "                affine=gad_nib.affine,\n",
    "                header=gad_nib.header\n",
    "            )\n",
    "\n",
    "            os.makedirs(f'{output_dir_test}/bids/{sub}/ses-pre/anat', exist_ok=True) # save in bids format\n",
    "            output_path = f'{output_dir_test}/bids/{sub}/ses-pre/anat/{degad_name}'\n",
    "            nib.save(degad_nib, output_path)\n",
    "    \n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
