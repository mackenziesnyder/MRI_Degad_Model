PATCH_SIZES = [32]
BATCH_SIZES = [256]
LEARNING_RATES = [0.0005]
INITIAL_FILTER = [512]
DEPTHS = [3,4]
NUM_CONVS = [2]
LOSS = ['mae']
TMP_DIR =  os.environ.get("SLURM_TMPDIR", "/tmp")

output_dir = config["output_dir"]
patch_dir = config["input_dir"]
p_size = config["p_size"]

rule all:
    input:
        expand("output/patch-{p_size}_batch-{b_size}_LR-{lr}_filter-{filter}_depth-{depth}_convs-{convs}_loss-{loss}/model_log.txt", p_size=PATCH_SIZES, b_size=BATCH_SIZES, lr=LEARNING_RATES, filter=INITIAL_FILTER,depth=DEPTHS,convs=NUM_CONVS, loss= LOSS)
               
rule split_test_val_train:
    input: 
        patch_dir = patch_dir
    params:
        train_ratio = config["train_ratio"]
        val_ratio = config["val_ratio"]
        test_ratio = config["test_ratio"]
    output: 
        train = f"{output_dir}/data/train.txt" 
        val = f"{output_dir}/data/val.txt"
        test = f"{output_dir}/data/test.txt" 
    script: 'scripts/train_val_test.py'

rule concatenate:
    input:
        patch_dir = patch_dir
        train = f"{output_dir}/data/train.txt" 
        val = f"{output_dir}/data/val.txt"
    output: 
        train_dat = f"{output_dir}/patches_concatenated/training_samples_{p_size}.dat"
        val_dat = f"{output_dir}/patches_concatenated/validation_samples_{p_size}.dat"

rule train:
    input:
        train_dat = f"{output_dir}/patches_concatenated/training_samples_{p_size}.dat"
        val_dat = f"{output_dir}/patches_concatenated/validation_samples_{p_size}.dat"
    threads: 32
    output:
        out="output/patch-{p_size}_batch-{b_size}_LR-{lr}_filter-{filter}_depth-{depth}_convs-{convs}_loss-{loss}/model_log.txt"
    params:
        patch_size=lambda wildcards: wildcards.p_size,
        batch_size=lambda wildcards: wildcards.b_size,
        lr=lambda wildcards: wildcards.lr,
        ini_filter=lambda wildcards: wildcards.filter,
        depth=lambda wildcards: wildcards.depth,
        num_convs= lambda wildcards: wildcards.convs,
        loss=lambda wildcards: wildcards.loss
    shell:
        "python3 scripts/training_degad_CNN.py --input {input.train} {input.val} --patch_size {params.patch_size} --batch_size {params.batch_size} --lr {params.lr} --ini_filter {params.ini_filter} --depth {params.depth} --num_conv {params.num_convs} --loss {params.loss}  > {output.out}"